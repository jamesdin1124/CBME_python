"""
å…’ç§‘ CCC è©•ä¼°ç³»çµ± â€” è³‡æ–™é·ç§»å·¥å…·
Google Sheets â†’ Supabase ä¸€æ¬¡æ€§é·ç§» + å¢é‡åŒæ­¥ã€‚
"""

import streamlit as st
import pandas as pd
from datetime import datetime


def migrate_google_sheets_to_supabase(dry_run=True):
    """
    å°‡ Google Sheets æ­·å²è³‡æ–™é·ç§»åˆ° Supabaseã€‚

    Args:
        dry_run (bool): True = åƒ…é è¦½ï¼Œä¸å¯¦éš›å¯«å…¥
    """
    st.markdown("### ğŸ“¦ Google Sheets â†’ Supabase è³‡æ–™é·ç§»")

    # 1. è¼‰å…¥ Google Sheets è³‡æ–™
    from modules.google_connection import fetch_google_form_data
    spreadsheet_url = "https://docs.google.com/spreadsheets/d/1n4kc2d3Z-x9SvIDApPCCz2HSDO0wSrrk9Y5jReMhr-M/edit?usp=sharing"

    with st.spinner("æ­£åœ¨å¾ Google Sheets è¼‰å…¥è³‡æ–™..."):
        df, sheet_titles = fetch_google_form_data(spreadsheet_url=spreadsheet_url)

    if df is None or df.empty:
        st.error("âŒ ç„¡æ³•å¾ Google Sheets è¼‰å…¥è³‡æ–™")
        return

    st.success(f"âœ… å·²å¾ Google Sheets è¼‰å…¥ {len(df)} ç­†è³‡æ–™")

    # 2. å‰è™•ç†
    from pages.pediatric.pediatric_analysis import process_pediatric_data
    processed_df = process_pediatric_data(df)

    # 3. åˆ†é¡è¨˜éŒ„
    technical_records = []
    meeting_records = []
    epa_records = []
    skipped = 0

    for _, row in processed_df.iterrows():
        eval_item = str(row.get('è©•æ ¸é …ç›®', '')).strip()

        if eval_item == 'æ“ä½œæŠ€è¡“':
            technical_records.append(_to_technical(row))
        elif eval_item == 'æœƒè­°å ±å‘Š':
            meeting_records.append(_to_meeting(row))
        elif 'EPA' in eval_item:
            epa_records.append(_to_epa(row))
        else:
            skipped += 1

    st.markdown(f"""
    **åˆ†é¡çµæœï¼š**
    - æ“ä½œæŠ€è¡“ï¼š**{len(technical_records)}** ç­†
    - æœƒè­°å ±å‘Šï¼š**{len(meeting_records)}** ç­†
    - EPAï¼š**{len(epa_records)}** ç­†
    - è·³éï¼ˆç„¡æ³•åˆ†é¡ï¼‰ï¼š{skipped} ç­†
    """)

    # 4. Dry run é è¦½
    if dry_run:
        st.warning("âš ï¸ **DRY RUN æ¨¡å¼** â€” ä¸æœƒå¯¦éš›å¯«å…¥è³‡æ–™")

        if technical_records:
            with st.expander(f"é è¦½æ“ä½œæŠ€è¡“ï¼ˆå‰ 5 ç­† / å…± {len(technical_records)} ç­†ï¼‰"):
                st.json(technical_records[:5])
        if meeting_records:
            with st.expander(f"é è¦½æœƒè­°å ±å‘Šï¼ˆå‰ 5 ç­† / å…± {len(meeting_records)} ç­†ï¼‰"):
                st.json(meeting_records[:5])
        if epa_records:
            with st.expander(f"é è¦½ EPAï¼ˆå‰ 5 ç­† / å…± {len(epa_records)} ç­†ï¼‰"):
                st.json(epa_records[:5])
        return

    # 5. æ­£å¼é·ç§»
    from modules.supabase_connection import SupabaseConnection
    conn = SupabaseConnection()
    total_inserted = 0
    errors = []

    with st.spinner("æ­£åœ¨å¯«å…¥ Supabase..."):
        # æ“ä½œæŠ€è¡“
        if technical_records:
            count = conn.insert_pediatric_evaluations_batch(technical_records)
            total_inserted += count
            if count < len(technical_records):
                errors.append(f"æ“ä½œæŠ€è¡“ï¼šé æœŸ {len(technical_records)} ç­†ï¼Œå¯¦éš› {count} ç­†")
            st.success(f"âœ… æ“ä½œæŠ€è¡“ï¼š{count} ç­†")

        # æœƒè­°å ±å‘Š
        if meeting_records:
            count = conn.insert_pediatric_evaluations_batch(meeting_records)
            total_inserted += count
            if count < len(meeting_records):
                errors.append(f"æœƒè­°å ±å‘Šï¼šé æœŸ {len(meeting_records)} ç­†ï¼Œå¯¦éš› {count} ç­†")
            st.success(f"âœ… æœƒè­°å ±å‘Šï¼š{count} ç­†")

        # EPA
        if epa_records:
            count = conn.insert_pediatric_evaluations_batch(epa_records)
            total_inserted += count
            if count < len(epa_records):
                errors.append(f"EPAï¼šé æœŸ {len(epa_records)} ç­†ï¼Œå¯¦éš› {count} ç­†")
            st.success(f"âœ… EPAï¼š{count} ç­†")

    # 6. è¨˜éŒ„ log
    status = 'success' if not errors else 'partial'
    conn.log_pediatric_migration(
        record_count=total_inserted,
        migration_type='initial',
        status=status,
        migrated_by=st.session_state.get('username', 'system'),
        error_details={'errors': errors} if errors else None
    )

    if errors:
        st.warning(f"âš ï¸ éƒ¨åˆ†é·ç§»å¤±æ•—ï¼š{'; '.join(errors)}")
    else:
        st.success(f"ğŸ‰ é·ç§»å®Œæˆï¼å…±å¯«å…¥ {total_inserted} ç­†è³‡æ–™")
        st.balloons()


def migrate_test_data_to_supabase():
    """å°‡æœ¬åœ°æ¸¬è©¦è³‡æ–™é·ç§»åˆ° Supabaseï¼ˆé–‹ç™¼ç”¨ï¼‰"""
    import os
    test_path = 'pages/pediatric/test_data_pediatric_evaluations.csv'
    if not os.path.exists(test_path):
        st.error(f"âŒ æ¸¬è©¦è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼š{test_path}")
        return

    df = pd.read_csv(test_path, encoding='utf-8-sig')
    st.success(f"âœ… å·²è¼‰å…¥æ¸¬è©¦è³‡æ–™ {len(df)} ç­†")

    from pages.pediatric.pediatric_analysis import process_pediatric_data
    processed_df = process_pediatric_data(df)

    records = []
    for _, row in processed_df.iterrows():
        eval_item = str(row.get('è©•æ ¸é …ç›®', '')).strip()
        if eval_item == 'æ“ä½œæŠ€è¡“':
            records.append(_to_technical(row))
        elif eval_item == 'æœƒè­°å ±å‘Š':
            records.append(_to_meeting(row))
        elif 'EPA' in eval_item:
            records.append(_to_epa(row))

    if not records:
        st.warning("ç„¡å¯é·ç§»çš„è¨˜éŒ„")
        return

    from modules.supabase_connection import SupabaseConnection
    conn = SupabaseConnection()

    with st.spinner(f"æ­£åœ¨å¯«å…¥ {len(records)} ç­†æ¸¬è©¦è³‡æ–™åˆ° Supabase..."):
        count = conn.insert_pediatric_evaluations_batch(records)

    conn.log_pediatric_migration(
        record_count=count,
        migration_type='manual',
        status='success' if count == len(records) else 'partial',
        migrated_by='test_data_migration'
    )

    st.success(f"âœ… å·²å¯«å…¥ {count} / {len(records)} ç­†æ¸¬è©¦è³‡æ–™")


# â”€â”€â”€ è½‰æ›å‡½æ•¸ â”€â”€â”€

def _safe_str(val):
    """å®‰å…¨è½‰æ›ç‚ºå­—ä¸²ï¼ŒNone/NaN å›å‚³ None"""
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    return str(val).strip() or None


def _safe_float(val):
    """å®‰å…¨è½‰æ›ç‚º floatï¼Œå¤±æ•—å›å‚³ None"""
    if val is None:
        return None
    try:
        v = float(val)
        return v if not pd.isna(v) else None
    except (ValueError, TypeError):
        return None


def _safe_int(val):
    """å®‰å…¨è½‰æ›ç‚º intï¼Œå¤±æ•—å›å‚³ None"""
    f = _safe_float(val)
    return int(f) if f is not None else None


def _safe_date(val):
    """å®‰å…¨è½‰æ›ç‚ºæ—¥æœŸå­—ä¸² YYYY-MM-DD"""
    if val is None:
        return str(datetime.now().date())
    try:
        if hasattr(val, 'isoformat'):
            return val.isoformat()
        return str(pd.to_datetime(val).date())
    except Exception:
        return str(datetime.now().date())


def _to_technical(row):
    """DataFrame è¡Œ â†’ æ“ä½œæŠ€è¡“ Supabase è¨˜éŒ„"""
    return {
        'evaluation_type': 'technical_skill',
        'evaluator_teacher': _safe_str(row.get('è©•æ ¸æ•™å¸«')) or 'æœªçŸ¥',
        'evaluation_date': _safe_date(row.get('è©•æ ¸æ—¥æœŸ')),
        'evaluated_resident': _safe_str(row.get('å—è©•æ ¸äººå“¡')) or 'æœªçŸ¥',
        'resident_level': _safe_str(row.get('è©•æ ¸æ™‚ç´šè·')),
        'evaluation_item': 'æ“ä½œæŠ€è¡“',
        'patient_id': _safe_str(row.get('ç—…æ­·è™Ÿ')),
        'technical_skill_item': _safe_str(row.get('è©•æ ¸æŠ€è¡“é …ç›®')),
        'sedation_medication': _safe_str(row.get('é®éœè—¥ç‰©')),
        'reliability_level': _safe_float(row.get('å¯ä¿¡è³´ç¨‹åº¦_æ•¸å€¼')),
        'technical_feedback': _safe_str(row.get('æ“ä½œæŠ€è¡“æ•™å¸«å›é¥‹')),
        'proficiency_level': _safe_int(row.get('ç†Ÿç·´ç¨‹åº¦_æ•¸å€¼')),
        'submitted_by': 'migration',
        'form_version': '1.0',
    }


def _to_meeting(row):
    """DataFrame è¡Œ â†’ æœƒè­°å ±å‘Š Supabase è¨˜éŒ„"""
    return {
        'evaluation_type': 'meeting_report',
        'evaluator_teacher': _safe_str(row.get('è©•æ ¸æ•™å¸«')) or 'æœªçŸ¥',
        'evaluation_date': _safe_date(row.get('è©•æ ¸æ—¥æœŸ')),
        'evaluated_resident': _safe_str(row.get('å—è©•æ ¸äººå“¡')) or 'æœªçŸ¥',
        'resident_level': _safe_str(row.get('è©•æ ¸æ™‚ç´šè·')),
        'evaluation_item': 'æœƒè­°å ±å‘Š',
        'meeting_name': _safe_str(row.get('æœƒè­°åç¨±')),
        'content_sufficient': _safe_int(row.get('å…§å®¹æ˜¯å¦å……åˆ†_æ•¸å€¼')),
        'data_analysis_ability': _safe_int(row.get('è¾¯è­‰è³‡æ–™çš„èƒ½åŠ›_æ•¸å€¼')),
        'presentation_clarity': _safe_int(row.get('å£æ¢ã€å‘ˆç¾æ–¹å¼æ˜¯å¦æ¸…æ™°_æ•¸å€¼')),
        'innovative_ideas': _safe_int(row.get('æ˜¯å¦å…·é–‹å‰µã€å»ºè¨­æ€§çš„æƒ³æ³•_æ•¸å€¼')),
        'logical_response': _safe_int(row.get('å›ç­”æå•æ˜¯å¦å…·é‚è¼¯ã€æœ‰æ¢æœ‰ç†_æ•¸å€¼')),
        'meeting_feedback': _safe_str(row.get('æœƒè­°å ±å‘Šæ•™å¸«å›é¥‹')),
        'submitted_by': 'migration',
        'form_version': '1.0',
    }


def _to_epa(row):
    """DataFrame è¡Œ â†’ EPA Supabase è¨˜éŒ„"""
    return {
        'evaluation_type': 'epa',
        'evaluator_teacher': _safe_str(row.get('è©•æ ¸æ•™å¸«')) or 'æœªçŸ¥',
        'evaluation_date': _safe_date(row.get('è©•æ ¸æ—¥æœŸ')),
        'evaluated_resident': _safe_str(row.get('å—è©•æ ¸äººå“¡')) or 'æœªçŸ¥',
        'resident_level': _safe_str(row.get('è©•æ ¸æ™‚ç´šè·')),
        'evaluation_item': 'EPA',
        'epa_item': _safe_str(row.get('EPAé …ç›®')),
        'epa_reliability_level': _safe_float(row.get('EPAå¯ä¿¡è³´ç¨‹åº¦_æ•¸å€¼')),
        'epa_qualitative_feedback': _safe_str(row.get('EPAè³ªæ€§å›é¥‹')),
        'submitted_by': 'migration',
        'form_version': '1.0',
    }
