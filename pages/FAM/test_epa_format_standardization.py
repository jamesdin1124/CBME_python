#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–åŠŸèƒ½
"""

import pandas as pd
import sys
import os

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)

def test_epa_format_standardization():
    """æ¸¬è©¦EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–åŠŸèƒ½"""
    try:
        from pages.FAM.fam_data_processor import FAMDataProcessor
        
        print("ğŸš€ é–‹å§‹æ¸¬è©¦EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–åŠŸèƒ½...")
        
        # è®€å–åŸå§‹EPAåŒ¯å‡ºæª”æ¡ˆ
        original_csv_path = os.path.join(os.path.dirname(__file__), 'EPAåŒ¯å‡ºåŸå§‹æª”_1140923.csv')
        
        if os.path.exists(original_csv_path):
            print(f"âœ… æ‰¾åˆ°åŸå§‹EPAåŒ¯å‡ºæª”æ¡ˆ")
            df_original = pd.read_csv(original_csv_path, encoding='utf-8')
            print(f"ğŸ“Š åŸå§‹æª”æ¡ˆå½¢ç‹€: {df_original.shape}")
            
            # åˆå§‹åŒ–è™•ç†å™¨
            processor = FAMDataProcessor()
            
            # æ¸…ç†è³‡æ–™ï¼ˆåŒ…å«æ ¼å¼æ¨™æº–åŒ–ï¼‰
            cleaned_df = processor.clean_data(df_original, debug=True)
            print(f"âœ… è³‡æ–™æ¸…ç†å®Œæˆ: {cleaned_df.shape}")
            
            # æª¢æŸ¥ç‰¹å®šè¨˜éŒ„
            target_patient = "1034498"
            target_name = "é¡§å°è²"
            
            print(f"\nğŸ” æª¢æŸ¥ç‰¹å®šè¨˜éŒ„è™•ç†çµæœ:")
            print(f"  ç—…æ­·è™Ÿç¢¼: {target_patient}")
            print(f"  å€‹æ¡ˆå§“å: {target_name}")
            
            if 'ç—…æ­·è™Ÿç¢¼' in cleaned_df.columns:
                matching_records = cleaned_df[cleaned_df['ç—…æ­·è™Ÿç¢¼'] == target_patient]
                print(f"  æ¸…ç†å¾Œæ‰¾åˆ° {len(matching_records)} ç­†åŒ¹é…è¨˜éŒ„")
                
                if not matching_records.empty:
                    print(f"\nğŸ“‹ æ¸…ç†å¾Œè¨˜éŒ„è©³æƒ…:")
                    for idx, row in matching_records.iterrows():
                        print(f"  è¨˜éŒ„ {idx}:")
                        print(f"    æ—¥æœŸ: {row.get('æ—¥æœŸ', 'N/A')}")
                        print(f"    EPAé …ç›®: '{row.get('EPAé …ç›®', 'N/A')}'")
                        print(f"    ç—…æ­·è™Ÿç¢¼: {row.get('ç—…æ­·è™Ÿç¢¼', 'N/A')}")
                        print(f"    å€‹æ¡ˆå§“å: {row.get('å€‹æ¡ˆå§“å', 'N/A')}")
                        print(f"    è¨ºæ–·: {row.get('è¨ºæ–·', 'N/A')}")
                        print(f"    è¤‡é›œç¨‹åº¦: {row.get('è¤‡é›œç¨‹åº¦', 'N/A')}")
                        print(f"    è§€å¯Ÿå ´åŸŸ: {row.get('è§€å¯Ÿå ´åŸŸ', 'N/A')}")
                        print(f"    ä¿¡è³´ç¨‹åº¦: {row.get('ä¿¡è³´ç¨‹åº¦(æ•™å¸«è©•é‡)', 'N/A')}")
                        print(f"    å­¸å“¡: {row.get('å­¸å“¡', 'N/A')}")
                else:
                    print(f"  âŒ æ¸…ç†å¾Œæ²’æœ‰æ‰¾åˆ°åŒ¹é…è¨˜éŒ„")
            
            # æª¢æŸ¥é„§ç¥–å¶¸çš„è³‡æ–™
            print(f"\nğŸ‘¥ æª¢æŸ¥é„§ç¥–å¶¸çš„è³‡æ–™:")
            if 'å­¸å“¡' in cleaned_df.columns:
                deng_records = cleaned_df[cleaned_df['å­¸å“¡'] == 'é„§ç¥–å¶¸']
                print(f"  é„§ç¥–å¶¸çš„è¨˜éŒ„æ•¸: {len(deng_records)}")
                
                if not deng_records.empty:
                    # æª¢æŸ¥EPAé …ç›®åˆ†ä½ˆ
                    epa_counts = deng_records['EPAé …ç›®'].value_counts()
                    print(f"  ğŸ“Š é„§ç¥–å¶¸çš„EPAé …ç›®åˆ†ä½ˆ:")
                    for epa, count in epa_counts.items():
                        print(f"    {epa}: {count} ç­†")
                    
                    # æª¢æŸ¥EPA10è¨˜éŒ„
                    epa10_records = deng_records[deng_records['EPAé …ç›®'].str.contains('EPA10', na=False)]
                    print(f"  ğŸ¯ é„§ç¥–å¶¸çš„EPA10è¨˜éŒ„æ•¸: {len(epa10_records)}")
                    
                    if not epa10_records.empty:
                        print(f"  ğŸ“‹ EPA10è¨˜éŒ„è©³æƒ…:")
                        for idx, row in epa10_records.iterrows():
                            print(f"    è¨˜éŒ„ {idx}:")
                            print(f"      æ—¥æœŸ: {row.get('æ—¥æœŸ', 'N/A')}")
                            print(f"      EPAé …ç›®: '{row.get('EPAé …ç›®', 'N/A')}'")
                            print(f"      ç—…æ­·è™Ÿç¢¼: {row.get('ç—…æ­·è™Ÿç¢¼', 'N/A')}")
                            print(f"      å€‹æ¡ˆå§“å: {row.get('å€‹æ¡ˆå§“å', 'N/A')}")
                            print(f"      è¨ºæ–·: {row.get('è¨ºæ–·', 'N/A')}")
                            print(f"      ä¿¡è³´ç¨‹åº¦: {row.get('ä¿¡è³´ç¨‹åº¦(æ•™å¸«è©•é‡)', 'N/A')}")
            
            # æª¢æŸ¥æ‰€æœ‰EPAé …ç›®åˆ†ä½ˆ
            print(f"\nğŸ¯ æª¢æŸ¥æ‰€æœ‰EPAé …ç›®åˆ†ä½ˆ:")
            if 'EPAé …ç›®' in cleaned_df.columns:
                all_epa_counts = cleaned_df['EPAé …ç›®'].value_counts()
                print(f"  ğŸ“Š æ‰€æœ‰EPAé …ç›®åˆ†ä½ˆ:")
                for epa, count in all_epa_counts.items():
                    if epa and epa != '':
                        print(f"    {epa}: {count} ç­†")
            
            print(f"\nğŸ‰ EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–æ¸¬è©¦å®Œæˆï¼")
            return True
        else:
            print(f"âŒ æ‰¾ä¸åˆ°åŸå§‹EPAåŒ¯å‡ºæª”æ¡ˆ")
            return False
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 70)
    result = test_epa_format_standardization()
    print("=" * 70)
    
    if result:
        print("ğŸ‰ EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–æ¸¬è©¦æˆåŠŸï¼")
        print("\nğŸ’¡ æ”¹é€²èªªæ˜:")
        print("- æ·»åŠ äº†EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–åŠŸèƒ½")
        print("- çµ±ä¸€è™•ç†ä¸åŒæ ¼å¼çš„EPAé …ç›®åç¨±")
        print("- ç¢ºä¿EPA10.å‡ºé™¢æº–å‚™/ç…§è­·è½‰éŠœè¨˜éŒ„èƒ½è¢«æ­£ç¢ºè™•ç†")
        print("- ç¾åœ¨æ‡‰è©²èƒ½åœ¨è©³ç´°è©•æ ¸è¨˜éŒ„ä¸­çœ‹åˆ°é€™å€‹è¨˜éŒ„")
    else:
        print("âŒ EPAé …ç›®æ ¼å¼æ¨™æº–åŒ–æ¸¬è©¦å¤±æ•—ï¼")
