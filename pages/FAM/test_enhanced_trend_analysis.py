#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦å¢å¼·ç‰ˆEPAé …ç›®è¶¨å‹¢åˆ†æåŠŸèƒ½
"""

import pandas as pd
import os
from fam_data_processor import FAMDataProcessor
from fam_visualization import FAMVisualization

def test_enhanced_trend_analysis():
    """æ¸¬è©¦å¢å¼·ç‰ˆè¶¨å‹¢åˆ†æåŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦å¢å¼·ç‰ˆEPAé …ç›®è¶¨å‹¢åˆ†æåŠŸèƒ½...")
    
    # è¼‰å…¥æ•´åˆè³‡æ–™
    integrated_file = "/Users/mbpr/Library/Mobile Documents/com~apple~CloudDocs/Python/CBME_python/pages/FAM/integrated_epa_data.csv"
    
    if not os.path.exists(integrated_file):
        print("âŒ æ•´åˆè³‡æ–™æª”æ¡ˆä¸å­˜åœ¨")
        return False
    
    try:
        # è¼‰å…¥è³‡æ–™
        df = pd.read_csv(integrated_file, encoding='utf-8')
        print(f"âœ… æˆåŠŸè¼‰å…¥æ•´åˆè³‡æ–™: {len(df)} ç­†è¨˜éŒ„")
        
        # åˆå§‹åŒ–è™•ç†å™¨å’Œè¦–è¦ºåŒ–æ¨¡çµ„
        processor = FAMDataProcessor()
        visualizer = FAMVisualization()
        
        # æ¸…ç†è³‡æ–™
        cleaned_df = processor.clean_data(df)
        print(f"âœ… è³‡æ–™æ¸…ç†å®Œæˆ: {len(cleaned_df)} ç­†è¨˜éŒ„")
        
        # æ¸¬è©¦è³‡æ–™ä¾†æºçµ±è¨ˆ
        if 'è³‡æ–™ä¾†æº' in cleaned_df.columns:
            source_counts = cleaned_df['è³‡æ–™ä¾†æº'].value_counts()
            print(f"âœ… è³‡æ–™ä¾†æºåˆ†å¸ƒ: {source_counts.to_dict()}")
        
        # æ¸¬è©¦å­¸å“¡æ¸…å–®
        students = processor.get_student_list(cleaned_df)
        print(f"âœ… å­¸å“¡æ¸…å–®: {len(students)} åå­¸å“¡")
        
        # æ¸¬è©¦EPAé …ç›®æ¸…å–®
        epa_items = processor.get_epa_items(cleaned_df)
        print(f"âœ… EPAé …ç›®æ¸…å–®: {len(epa_items)} ç¨®")
        print(f"   EPAé …ç›®: {list(epa_items)[:5]}")
        
        # æ¸¬è©¦å¢å¼·ç‰ˆè¶¨å‹¢åˆ†æåŠŸèƒ½
        if students and epa_items:
            test_student = students[0]
            test_epa = list(epa_items)[0]
            
            print(f"\\nğŸ§ª æ¸¬è©¦å­¸å“¡: {test_student}, EPAé …ç›®: {test_epa}")
            
            # ç²å–å­¸å“¡çš„EPAè³‡æ–™
            student_data = cleaned_df[cleaned_df['å­¸å“¡'] == test_student]
            epa_data = student_data[student_data['EPAé …ç›®'] == test_epa]
            
            print(f"   è©²å­¸å“¡çš„{test_epa}è³‡æ–™: {len(epa_data)} ç­†è¨˜éŒ„")
            
            if 'è³‡æ–™ä¾†æº' in epa_data.columns:
                source_counts = epa_data['è³‡æ–™ä¾†æº'].value_counts()
                print(f"   è³‡æ–™ä¾†æºåˆ†å¸ƒ: {source_counts.to_dict()}")
            
            # æ¸¬è©¦å¢å¼·ç‰ˆè¶¨å‹¢åœ–å‰µå»º
            enhanced_fig = visualizer.create_enhanced_monthly_trend_chart(
                epa_data, test_epa, test_student
            )
            
            if enhanced_fig is not None:
                print("âœ… å¢å¼·ç‰ˆè¶¨å‹¢åœ–å‰µå»ºæˆåŠŸ")
                
                # æª¢æŸ¥åœ–è¡¨é…ç½®
                layout = enhanced_fig.layout
                print(f"   åœ–è¡¨æ¨™é¡Œ: {layout.title.text}")
                print(f"   Xè»¸æ¨™é¡Œ: {layout.xaxis.title.text}")
                print(f"   Yè»¸æ¨™é¡Œ: {layout.yaxis.title.text}")
                
                # æª¢æŸ¥è³‡æ–™ç³»åˆ—
                traces = enhanced_fig.data
                print(f"   è³‡æ–™ç³»åˆ—æ•¸é‡: {len(traces)}")
                for i, trace in enumerate(traces):
                    print(f"     ç³»åˆ—{i+1}: {trace.name} (æ¨¡å¼: {trace.mode})")
            else:
                print("âš ï¸ å¢å¼·ç‰ˆè¶¨å‹¢åœ–å‰µå»ºå¤±æ•—ï¼Œå¯èƒ½æ²’æœ‰è¶³å¤ çš„è³‡æ–™")
        
        # æ¸¬è©¦å¤šå€‹å­¸å“¡å’ŒEPAé …ç›®çš„çµ„åˆ
        print(f"\\nğŸ§ª æ¸¬è©¦å¤šå€‹å­¸å“¡EPAé …ç›®çµ„åˆ...")
        test_combinations = []
        
        for student in students[:3]:  # æ¸¬è©¦å‰3åå­¸å“¡
            student_data = cleaned_df[cleaned_df['å­¸å“¡'] == student]
            student_epa_items = student_data['EPAé …ç›®'].unique()
            
            for epa_item in student_epa_items[:2]:  # æ¯å€‹å­¸å“¡æ¸¬è©¦å‰2å€‹EPAé …ç›®
                epa_data = student_data[student_data['EPAé …ç›®'] == epa_item]
                if len(epa_data) > 0:
                    test_combinations.append((student, epa_item, len(epa_data)))
        
        print(f"   æ‰¾åˆ° {len(test_combinations)} å€‹æœ‰æ•ˆçš„å­¸å“¡-EPAçµ„åˆ")
        for student, epa_item, count in test_combinations[:5]:
            print(f"   {student} - {epa_item}: {count} ç­†è¨˜éŒ„")
        
        print("\\nğŸ‰ å¢å¼·ç‰ˆè¶¨å‹¢åˆ†æåŠŸèƒ½æ¸¬è©¦å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        import traceback
        print(f"è©³ç´°éŒ¯èª¤ä¿¡æ¯: {traceback.format_exc()}")
        return False

def test_data_source_filtering():
    """æ¸¬è©¦è³‡æ–™ä¾†æºéæ¿¾åŠŸèƒ½"""
    print("\\nğŸ§ª æ¸¬è©¦è³‡æ–™ä¾†æºéæ¿¾åŠŸèƒ½...")
    
    integrated_file = "/Users/mbpr/Library/Mobile Documents/com~apple~CloudDocs/Python/CBME_python/pages/FAM/integrated_epa_data.csv"
    
    try:
        df = pd.read_csv(integrated_file, encoding='utf-8')
        processor = FAMDataProcessor()
        cleaned_df = processor.clean_data(df)
        
        if 'è³‡æ–™ä¾†æº' in cleaned_df.columns:
            sources = cleaned_df['è³‡æ–™ä¾†æº'].unique()
            print(f"âœ… å¯ç”¨è³‡æ–™ä¾†æº: {list(sources)}")
            
            # æ¸¬è©¦æ¯å€‹è³‡æ–™ä¾†æºçš„éæ¿¾
            for source in sources:
                filtered_df = cleaned_df[cleaned_df['è³‡æ–™ä¾†æº'] == source]
                students_in_source = filtered_df['å­¸å“¡'].nunique()
                epa_items_in_source = filtered_df['EPAé …ç›®'].nunique()
                
                print(f"   {source}: {len(filtered_df)} ç­†è¨˜éŒ„, {students_in_source} åå­¸å“¡, {epa_items_in_source} ç¨®EPAé …ç›®")
                
                # æ¸¬è©¦è©²ä¾†æºçš„è¶¨å‹¢åˆ†æ
                if students_in_source > 0 and epa_items_in_source > 0:
                    test_student = filtered_df['å­¸å“¡'].iloc[0]
                    test_epa = filtered_df['EPAé …ç›®'].iloc[0]
                    
                    student_epa_data = filtered_df[
                        (filtered_df['å­¸å“¡'] == test_student) & 
                        (filtered_df['EPAé …ç›®'] == test_epa)
                    ]
                    
                    print(f"     æ¸¬è©¦çµ„åˆ {test_student} - {test_epa}: {len(student_epa_data)} ç­†è¨˜éŒ„")
        
        print("âœ… è³‡æ–™ä¾†æºéæ¿¾åŠŸèƒ½æ¸¬è©¦å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ è³‡æ–™ä¾†æºéæ¿¾æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False

def main():
    """ä¸»æ¸¬è©¦ç¨‹å¼"""
    print("=" * 60)
    print("ğŸ§ª å¢å¼·ç‰ˆEPAé …ç›®è¶¨å‹¢åˆ†æåŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    # æ¸¬è©¦å¢å¼·ç‰ˆè¶¨å‹¢åˆ†æ
    test1_result = test_enhanced_trend_analysis()
    
    # æ¸¬è©¦è³‡æ–™ä¾†æºéæ¿¾
    test2_result = test_data_source_filtering()
    
    print("\\n" + "=" * 60)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 60)
    
    if test1_result and test2_result:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å¢å¼·ç‰ˆè¶¨å‹¢åˆ†æåŠŸèƒ½å·²æº–å‚™å°±ç·’ï¼")
        print("\\nâœ… æ–°åŠŸèƒ½åŒ…æ‹¬:")
        print("   â€¢ æ”¯æ´å¤šè³‡æ–™ä¾†æºçš„è¶¨å‹¢åˆ†æ")
        print("   â€¢ è³‡æ–™ä¾†æºéæ¿¾é¸é …")
        print("   â€¢ å¢å¼·ç‰ˆè¦–è¦ºåŒ–åœ–è¡¨")
        print("   â€¢ å€åˆ†EMYWAYæ­·å²è³‡æ–™å’Œç¾æœ‰ç³»çµ±è³‡æ–™")
        print("   â€¢ è©³ç´°çš„è³‡æ–™ä¾†æºçµ±è¨ˆ")
    else:
        print("âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
