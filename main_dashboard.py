import streamlit as st
import httpx
import sqlite3
from datetime import datetime

# è¨­å®šé é¢é…ç½®ç‚ºå¯¬å±æ¨¡å¼
st.set_page_config(
    layout="wide",  # ä½¿ç”¨å¯¬å±æ¨¡å¼
    page_title="å­¸ç”Ÿè©•æ ¸ç³»çµ±",
    initial_sidebar_state="expanded"  # é è¨­å±•é–‹å´é‚Šæ¬„
)

import pandas as pd
import os
import re
import sys  # åŒ¯å…¥ sys
from io import BytesIO
from analysis_pgy_students import show_analysis_section
from analysis_residents import show_resident_analysis_section
from analysis_anesthesia_residents import show_ANE_R_EPA_peer_analysis_section
from analysis_teachers import show_teacher_analysis_section, fetch_google_form_data
from analysis_ugy_peers import show_UGY_peer_analysis_section
from analysis_ugy_overview import show_ugy_student_overview
from analysis_ugy_individual import show_ugy_student_analysis
from modules.epa_constants import EPA_LEVEL_MAPPING
from modules.auth import show_login_page, show_user_management, check_permission, USER_ROLES, show_registration_page, filter_data_by_permission, get_user_department
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from openai import OpenAI
from dotenv import load_dotenv
import traceback # åŒ¯å…¥ traceback
from supabase import create_client

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def get_openai_client():
    """ç²å– OpenAI å®¢æˆ¶ç«¯å¯¦ä¾‹ä¸¦æä¾›æ›´è©³ç´°çš„éŒ¯èª¤è¨Šæ¯ï¼Œä½¿ç”¨è‡ªè¨‚ httpx å®¢æˆ¶ç«¯"""
    try:
        # é‡æ–°è¼‰å…¥ .env æª”æ¡ˆä»¥ç¢ºä¿å–å¾—æœ€æ–°è¨­å®š
        load_dotenv(override=True)
        
        # è®€å– API é‡‘é‘°
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            st.error("âŒ éŒ¯èª¤ï¼šæœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° OPENAI_API_KEYã€‚")
            st.error("""
            è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šæ­£ç¢ºçš„ OpenAI API é‡‘é‘°ï¼š
            OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
            
            OpenAI API é‡‘é‘°æ‡‰è©²æ˜¯ä»¥ sk-proj- æˆ– sk- é–‹é ­çš„ä¸€ä¸²è‹±æ–‡å­—æ¯å’Œæ•¸å­—ã€‚
            è«‹ç¢ºä¿ï¼š
            1. é‡‘é‘°å®Œæ•´è¤‡è£½ï¼ˆé€šå¸¸ç´„ 40-50 å€‹å­—å…ƒï¼‰
            2. æ²’æœ‰æ›è¡Œç¬¦è™Ÿ
            3. æ²’æœ‰å¤šé¤˜çš„å¼•è™Ÿæˆ–ç©ºæ ¼
            4. æ•´å€‹é‡‘é‘°éƒ½åœ¨åŒä¸€è¡Œ
            """)
            return None
            
        # æ¸…ç†å’Œé©—è­‰ API é‡‘é‘°
        api_key = api_key.strip().strip('"').strip("'")
        
        # æª¢æŸ¥é‡‘é‘°æ ¼å¼
        if not (api_key.startswith("sk-proj-") or api_key.startswith("sk-")):
            st.error("âŒ API é‡‘é‘°æ ¼å¼ä¸æ­£ç¢ºï¼šé‡‘é‘°å¿…é ˆä»¥ 'sk-proj-' æˆ– 'sk-' é–‹é ­")
            return None
            
        # å»ºç«‹ HTTP å®¢æˆ¶ç«¯
        http_client = httpx.Client(
            trust_env=False,  # ä¸ä½¿ç”¨ç³»çµ±ä»£ç†è¨­å®š
            timeout=30.0      # è¨­å®šè¶…æ™‚æ™‚é–“
        )
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        client = OpenAI(
            api_key=api_key,
            http_client=http_client
        )
        st.success("âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        return client
        
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        st.error(f"è©³ç´°è¿½è¹¤ï¼š\n{traceback.format_exc()}")
        return None

# åˆå§‹åŒ– session state
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False

def merge_excel_files(uploaded_files):
    """
    åˆä½µä¸Šå‚³çš„å¤šå€‹ Excel æª”æ¡ˆã€‚

    Args:
        uploaded_files (list): Streamlit file_uploader ä¸Šå‚³çš„æª”æ¡ˆåˆ—è¡¨ã€‚

    Returns:
        pandas.DataFrame or None: åˆä½µå¾Œçš„ DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› Noneã€‚
    """
    try:
        if not uploaded_files:
            st.warning("è«‹ä¸Šå‚³Excelæª”æ¡ˆï¼")
            return None

        all_data = []
        all_columns = set() # è¨˜éŒ„æ‰€æœ‰æª”æ¡ˆä¸­å‡ºç¾éçš„æ¬„ä½
        epa_related_columns = set() # è¨˜éŒ„æ‰€æœ‰ EPA ç›¸é—œæ¬„ä½ (æ•™å¸«è©•æ ¸, å­¸å“¡è‡ªè©•, EPA)

        # ç¬¬ä¸€éï¼šè®€å–æª”æ¡ˆï¼Œé è™•ç†ï¼Œä¸¦æ”¶é›†æ‰€æœ‰æ¬„ä½åç¨±
        for uploaded_file in uploaded_files:
            # è®€å– Excel æª”æ¡ˆ
            try:
                df = pd.read_excel(uploaded_file)
            except Exception as read_error:
                st.error(f"è®€å–æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {read_error}")
                continue # è·³éé€™å€‹æª”æ¡ˆ

            # è™•ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤æ‹¬è™Ÿå…§çš„ç‰ˆæœ¬è™Ÿ
            clean_filename = re.sub(r'\s*\([0-9]+\)\.xls$', '.xls', uploaded_file.name)
            df['æª”æ¡ˆåç¨±'] = clean_filename # å…ˆåŠ å…¥æª”æ¡ˆåç¨±

            # è¨˜éŒ„åŸå§‹æ¬„ä½
            all_columns.update(df.columns)

            # è™•ç†è¨“ç·´éšæ®µæœŸé–“
            if 'è¨“ç·´éšæ®µæœŸé–“' in df.columns:
                try:
                    # å°‡æœŸé–“å­—ä¸²åˆ†å‰²æˆé–‹å§‹å’ŒçµæŸæ—¥æœŸ
                    date_extracted = df['è¨“ç·´éšæ®µæœŸé–“'].str.extract(r'(\d{4}-\d{2}-\d{2})\s*~\s*(\d{4}-\d{2}-\d{2})')
                    df[['é–‹å§‹æ—¥æœŸ', 'çµæŸæ—¥æœŸ']] = date_extracted

                    # è½‰æ›ç‚ºæ—¥æœŸæ ¼å¼
                    df['é–‹å§‹æ—¥æœŸ'] = pd.to_datetime(df['é–‹å§‹æ—¥æœŸ'], errors='coerce')
                    df['çµæŸæ—¥æœŸ'] = pd.to_datetime(df['çµæŸæ—¥æœŸ'], errors='coerce')

                    # è¨ˆç®—è¨“ç·´å¤©æ•¸ (åƒ…åœ¨æ—¥æœŸæœ‰æ•ˆæ™‚è¨ˆç®—)
                    valid_dates = df['é–‹å§‹æ—¥æœŸ'].notna() & df['çµæŸæ—¥æœŸ'].notna()
                    df.loc[valid_dates, 'è¨“ç·´å¤©æ•¸'] = (df.loc[valid_dates, 'çµæŸæ—¥æœŸ'] - df.loc[valid_dates, 'é–‹å§‹æ—¥æœŸ']).dt.days + 1
                    # è¨˜éŒ„æ–°å¢çš„æ¬„ä½
                    all_columns.update(['é–‹å§‹æ—¥æœŸ', 'çµæŸæ—¥æœŸ', 'è¨“ç·´å¤©æ•¸'])
                except Exception as date_error:
                    st.warning(f"è™•ç†æª”æ¡ˆ {uploaded_file.name} çš„ 'è¨“ç·´éšæ®µæœŸé–“' æ™‚ç™¼ç”ŸéŒ¯èª¤: {date_error}")
                    # å³ä½¿å‡ºéŒ¯ï¼Œä¹Ÿç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œé¿å…å¾ŒçºŒåˆä½µå•é¡Œ
                    if 'é–‹å§‹æ—¥æœŸ' not in df.columns: df['é–‹å§‹æ—¥æœŸ'] = pd.NaT
                    if 'çµæŸæ—¥æœŸ' not in df.columns: df['çµæŸæ—¥æœŸ'] = pd.NaT
                    if 'è¨“ç·´å¤©æ•¸' not in df.columns: df['è¨“ç·´å¤©æ•¸'] = pd.NA
                    all_columns.update(['é–‹å§‹æ—¥æœŸ', 'çµæŸæ—¥æœŸ', 'è¨“ç·´å¤©æ•¸'])

            # é è™•ç†æ¬„ä½å€¼ å’Œ è­˜åˆ¥ EPA ç›¸é—œæ¬„ä½
            cols_to_process = df.columns.tolist()
            for col in cols_to_process:
                # ç§»é™¤ç‰¹å®šæ–‡å­— (å…ˆè½‰æ›æˆå­—ä¸²é¿å…éŒ¯èª¤)
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace("æœ¬è¡¨å–®èˆ‡ç•¢æ¥­æˆç¸¾ç„¡é—œï¼Œè«‹ä¾å­¸ç”Ÿè¡¨ç¾è½å¯¦è©•é‡;", "", regex=False)

                is_epa_col = False
                if 'æ•™å¸«è©•æ ¸' in col or 'å­¸å“¡è‡ªè©•' in col or 'EPA' in col:
                    is_epa_col = True
                    original_col_name = f"{col} [åŸå§‹]"
                     # æª¢æŸ¥åŸå§‹æ¬„ä½æ˜¯å¦å·²å­˜åœ¨ (é¿å…é‡è¤‡æ·»åŠ )
                    if original_col_name not in df.columns:
                         df[original_col_name] = df[col].copy()
                         all_columns.add(original_col_name) # è¨˜éŒ„åŸå§‹æ¬„ä½åç¨±
                    epa_related_columns.add(col) # è¨˜éŒ„ EPA æ¬„ä½åç¨±
                    epa_related_columns.add(original_col_name) # ä¹Ÿè¨˜éŒ„åŸå§‹æ¬„ä½

                    # æ‡‰ç”¨ EPA ç­‰ç´šæ˜ å°„ (è½‰æ›å‰ç¢ºä¿æ˜¯å­—ä¸²)
                    df[col] = df[col].apply(lambda x: EPA_LEVEL_MAPPING.get(str(x).strip(), x))
                    # è½‰æ›ç‚ºæ•¸å€¼ï¼Œç„¡æ³•è½‰æ›çš„è®Šç‚º NaN
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            all_data.append(df)

        if not all_data:
            st.warning("æ²’æœ‰æˆåŠŸè®€å–çš„æª”æ¡ˆå¯ä¾›åˆä½µã€‚")
            return None

        # ç¬¬äºŒéï¼šç¢ºä¿æ‰€æœ‰ DataFrame éƒ½æœ‰æ‰€æœ‰æ¬„ä½ï¼Œç‰¹åˆ¥æ˜¯ EPA ç›¸é—œæ¬„ä½
        processed_data = []
        for df in all_data:
            # æ‰¾å‡ºç•¶å‰ df ç¼ºå°‘çš„æ¬„ä½
            missing_cols = all_columns - set(df.columns)
            for col in missing_cols:
                df[col] = pd.NA # ä½¿ç”¨ pandas çš„ NA æ¨™è¨˜ç¼ºå¤±å€¼ï¼Œæ›´é€šç”¨

             # ç‰¹åˆ¥æª¢æŸ¥ EPA ç›¸é—œæ¬„ä½ï¼Œå¦‚æœç¼ºå°‘å‰‡å¡« NaN (å› ç‚ºå®ƒå€‘é æœŸæ˜¯æ•¸å€¼)
            # æ³¨æ„ï¼šä¸Šä¸€æ­¥çš„ pd.NA å·²ç¶“è™•ç†äº†ï¼Œé€™è£¡å†ç¢ºèªä¸€æ¬¡ä»¥é˜²è¬ä¸€
            # for epa_col in epa_related_columns:
            #     if epa_col not in df.columns:
            #         # å¦‚æœæ˜¯è½‰æ›å¾Œçš„æ•¸å€¼æ¬„ä½ï¼Œå¡« NaN
            #         if not epa_col.endswith(" [åŸå§‹]"):
            #             df[epa_col] = pd.NA # pd.to_numeric æœƒè™•ç† pd.NA
            #         else: # å¦‚æœæ˜¯åŸå§‹æ¬„ä½ï¼Œä¹Ÿå¡« NA
            #             df[epa_col] = pd.NA
            processed_data.append(df)


        # åˆä½µæ‰€æœ‰DataFrameï¼Œsort=False ä¿æŒæ¬„ä½é †åºï¼Œä¸å­˜åœ¨çš„æ¬„ä½æœƒè‡ªå‹•å¡«å…… NaN
        try:
            merged_df = pd.concat(processed_data, ignore_index=True, sort=False)
        except Exception as concat_error:
            st.error(f"åˆä½µ DataFrame æ™‚ç™¼ç”ŸéŒ¯èª¤: {concat_error}")
            # å˜—è©¦æ‰¾å‡ºå“ªå€‹ DataFrame å°è‡´å•é¡Œ
            for i, df_check in enumerate(processed_data):
                 st.write(f"DataFrame {i} (ä¾†æº: {df_check['æª”æ¡ˆåç¨±'].iloc[0] if not df_check.empty else 'æœªçŸ¥'}) æ¬„ä½: {df_check.columns.tolist()}")
            return None


        # é‡æ–°æ’åºæ¬„ä½ï¼Œç¢ºä¿ 'æª”æ¡ˆåç¨±' åœ¨æœ€å‰é¢
        if 'æª”æ¡ˆåç¨±' in merged_df.columns:
            cols = merged_df.columns.tolist()
            cols.remove('æª”æ¡ˆåç¨±')
            merged_df = merged_df[['æª”æ¡ˆåç¨±'] + cols]
        else:
             st.warning("åˆä½µçµæœä¸­ç¼ºå°‘ 'æª”æ¡ˆåç¨±' æ¬„ä½ã€‚")


        # --- ä¸‹è¼‰æŒ‰éˆ•å’Œå„²å­˜åˆ° session state ---
        # å°‡åˆä½µå¾Œçš„è³‡æ–™è½‰æ›ç‚º CSV
        try:
            csv = merged_df.to_csv(index=False).encode('utf-8') # æŒ‡å®š utf-8 ç·¨ç¢¼
        except Exception as csv_error:
            st.error(f"è½‰æ›ç‚º CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {csv_error}")
            csv = None

        # å°‡åˆä½µå¾Œçš„è³‡æ–™è½‰æ›ç‚º Excel
        excel_buffer = BytesIO()
        try:
            merged_df.to_excel(excel_buffer, index=False, engine='openpyxl') # æ˜ç¢ºæŒ‡å®šå¼•æ“
            excel_data = excel_buffer.getvalue()
        except Exception as excel_error:
            st.error(f"è½‰æ›ç‚º Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {excel_error}")
            excel_data = None

        # å»ºç«‹å…©å€‹ä¸¦æ’çš„ä¸‹è¼‰æŒ‰éˆ• (åªæœ‰åœ¨æˆåŠŸè½‰æ›æ™‚æ‰é¡¯ç¤º)
        col1, col2 = st.columns(2)
        with col1:
            if csv:
                st.download_button(
                    label="ä¸‹è¼‰ CSV æª”æ¡ˆ",
                    data=csv,
                    file_name="merged_data.csv",
                    mime="text/csv"
                )
            else:
                st.warning("ç„¡æ³•ç”¢ç”Ÿ CSV æª”æ¡ˆã€‚")

        with col2:
            if excel_data:
                st.download_button(
                    label="ä¸‹è¼‰ Excel æª”æ¡ˆ",
                    data=excel_data,
                    file_name="merged_data.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("ç„¡æ³•ç”¢ç”Ÿ Excel æª”æ¡ˆã€‚")

        # åˆä½µå®Œæˆå¾Œå­˜å…¥ session state
        st.session_state.merged_data = merged_df
        return merged_df

    except Exception as e:
        st.error(f"åˆä½µæª”æ¡ˆéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š{str(e)}")
        import traceback
        st.error(traceback.format_exc()) # é¡¯ç¤ºè©³ç´°çš„éŒ¯èª¤è¿½è¹¤
        return None

def correct_text_with_gpt(text):
    """
    ä½¿ç”¨ GPT API ä¿®æ­£æ–‡å­—
    
    Args:
        text (str): éœ€è¦ä¿®æ­£çš„æ–‡å­—
        
    Returns:
        str: ä¿®æ­£å¾Œçš„æ–‡å­—
    """
    client = get_openai_client()
    if not client:
        st.warning("ç„¡æ³•ç²å– OpenAI å®¢æˆ¶ç«¯ï¼Œæ–‡å­—ä¿®æ­£åŠŸèƒ½ç„¡æ³•ä½¿ç”¨ã€‚")
        return text

    try:
        st.info("æ­£åœ¨å‘¼å« OpenAI API é€²è¡Œæ–‡å­—ä¿®æ­£...")
        
        # ç¢ºä¿æç¤ºæ–‡æœ¬æ˜¯æœ‰æ•ˆçš„ UTF-8 å­—ç¬¦ä¸²
        system_content = "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é†«å­¸æ•™è‚²æ–‡å­—ç·¨è¼¯åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯æ•´ç†è‡¨åºŠæ•™å¸«å°å¯¦ç¿’é†«å­¸ç”Ÿçš„å£é ­å›é¥‹ï¼Œä½¿å…¶æ›´æœ‰æ¢ç†ä¸”æ˜“æ–¼é–±è®€ã€‚è«‹ä¿æŒåŸæ„ï¼Œä½†å¯ä»¥ï¼š\n1. ä¿®æ­£éŒ¯åˆ¥å­—å’Œèªæ³•\n2. æ”¹å–„å¥å­çµæ§‹\n3. é©ç•¶åˆ†æ®µ\n4. ä½¿ç”¨æ›´å°ˆæ¥­çš„é†«å­¸ç”¨èª\n5. ä¿æŒè©•èªçš„å»ºè¨­æ€§å’Œæ•™è‚²æ„ç¾©\n\nè«‹ç›´æ¥è¿”å›ä¿®æ”¹å¾Œçš„æ–‡å­—ï¼Œä¸éœ€è¦å…¶ä»–èªªæ˜ã€‚"
        
        # é¡¯ç¤ºç”¨æ–¼è¨ºæ–·çš„ä¿¡æ¯
        st.info(f"ä½¿ç”¨è€…æ–‡å­—å­—ç¯€é•·åº¦ï¼š{len(text.encode('utf-8'))} bytes")
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": text}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        st.success("âœ… OpenAI API å‘¼å«æˆåŠŸï¼")
        return response.choices[0].message.content.strip()
    except Exception as e:
        # å®‰å…¨åœ°ç²å–éŒ¯èª¤è¨Šæ¯å­—ä¸²
        error_details = f"éŒ¯èª¤é¡å‹: {type(e).__name__}"
        try:
            error_message = str(e)
        except Exception:
            error_message = "ç„¡æ³•é¡¯ç¤ºçš„éŒ¯èª¤è¨Šæ¯ (ç·¨ç¢¼å•é¡Œ)"

        st.error(f"âŒ å‘¼å« OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error_message} ({error_details})", icon="ğŸš¨")
        tb_str = f"è©³ç´°è¿½è¹¤è³‡è¨Š:\n{traceback.format_exc()}"
        st.error(tb_str)
        return text

def init_test_form_db():
    """åˆå§‹åŒ–æ¸¬è©¦è¡¨å–®è³‡æ–™åº«"""
    try:
        conn = sqlite3.connect('test_form.db')
        cursor = conn.cursor()
        
        # å»ºç«‹æ¸¬è©¦è¡¨å–®è³‡æ–™è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS test_form_submissions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            batch TEXT NOT NULL,
            epa_1 INTEGER NOT NULL,
            epa_2 INTEGER NOT NULL,
            epa_3 INTEGER NOT NULL,
            epa_4 INTEGER NOT NULL,
            epa_5 INTEGER NOT NULL,
            comments TEXT,
            submitted_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"åˆå§‹åŒ–è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return False

def save_to_sqlite(form_data):
    """å°‡è¡¨å–®è³‡æ–™å„²å­˜åˆ° SQLite è³‡æ–™åº«"""
    try:
        conn = sqlite3.connect('test_form.db')
        cursor = conn.cursor()
        
        # æ’å…¥è³‡æ–™
        cursor.execute('''
        INSERT INTO test_form_submissions 
        (name, batch, epa_1, epa_2, epa_3, epa_4, epa_5, comments, submitted_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            form_data['å§“å'],
            form_data['æ¢¯æ¬¡'],
            form_data['EPA_1'],
            form_data['EPA_2'],
            form_data['EPA_3'],
            form_data['EPA_4'],
            form_data['EPA_5'],
            form_data['è©•èª'],
            form_data['æäº¤æ™‚é–“']
        ))
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"å„²å­˜è³‡æ–™åˆ°è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return False

def main():
    # æª¢æŸ¥æ˜¯å¦å·²ç™»å…¥
    if not st.session_state.logged_in:
        # å»ºç«‹é¸é …å¡è®“ç”¨æˆ¶é¸æ“‡ç™»å…¥æˆ–è¨»å†Š
        login_tab, register_tab, test_form_tab, test_result_tab = st.tabs(["ç™»å…¥", "ç”³è«‹å¸³è™Ÿ", "æ¸¬è©¦è¡¨å–®", "æ¸¬è©¦çµæœ"])
        
        with login_tab:
            if show_login_page():
                st.rerun()
        
        with register_tab:
            if show_registration_page():
                st.success("å¸³è™Ÿç”³è«‹æˆåŠŸï¼è«‹ç­‰å¾…ç®¡ç†å“¡å¯©æ ¸å¾Œå³å¯ç™»å…¥ã€‚")
                # ä¸éœ€è¦ç«‹å³é‡æ–°é‹è¡Œï¼Œè®“ç”¨æˆ¶çœ‹åˆ°æˆåŠŸè¨Šæ¯
                
        with test_form_tab:
            st.header("æ¸¬è©¦è¡¨å–®å¡«å¯«")
            
            # å…¶ä»–è©•èªï¼ˆè¡¨å–®å¤–ï¼‰
            st.subheader("å…¶ä»–è©•èª")
            comments = st.text_area("è«‹è¼¸å…¥è©•èª", height=100, key="input_comments")
            
            # æ–‡å­—ä¿®æ­£æŒ‰éˆ•ï¼ˆè¡¨å–®å¤–ï¼‰
            if comments:
                if st.button("ä¿®æ­£æ–‡å­—", key="correct_button"):
                    corrected_comments = correct_text_with_gpt(comments)
                    st.session_state.corrected_comments = corrected_comments
                    st.text_area("ä¿®æ­£å¾Œçš„è©•èª", corrected_comments, height=100, key="corrected_text")
                    comments = corrected_comments
            
            st.markdown("---")  # åˆ†éš”ç·š
            
            # ä½¿ç”¨è¡¨å–®å®¹å™¨
            with st.form("test_form", clear_on_submit=False):
                st.subheader("åŸºæœ¬è³‡è¨Š")
                col1, col2 = st.columns(2)
                with col1:
                    name = st.selectbox(
                        "å§“å",
                        ["ä¸OO"]
                    )
                with col2:
                    batch = st.selectbox(
                        "æ¢¯æ¬¡",
                        ["2025/02", "2025/03", "2025/04"]
                    )
                
                # EPA è©•åˆ†é …ç›®
                st.subheader("EPA è©•åˆ†")
                epa_scores = {}
                for i in range(1, 6):  # å‡è¨­æœ‰ 5 å€‹ EPA é …ç›®
                    epa_scores[f"EPA_{i}"] = st.slider(
                        f"EPA {i} è©•åˆ†",
                        min_value=1,
                        max_value=5,
                        value=3,
                        help="1: éœ€è¦ç›£ç£, 2: éœ€è¦æŒ‡å°, 3: éœ€è¦æç¤º, 4: ç¨ç«‹å®Œæˆ, 5: å¯æŒ‡å°ä»–äºº"
                    )
                
                # é¡¯ç¤ºæœ€çµ‚è©•èª
                st.subheader("æœ€çµ‚è©•èª")
                final_comments = st.text_area("ç¢ºèªè©•èª", comments, height=100, key="final_comments", disabled=True)
                
                # æäº¤æŒ‰éˆ•
                submitted = st.form_submit_button("æäº¤è¡¨å–®")
                
                if submitted:
                    # å»ºç«‹è³‡æ–™å­—å…¸
                    form_data = {
                        "å§“å": name,
                        "æ¢¯æ¬¡": batch,
                        "EPA_1": epa_scores["EPA_1"],
                        "EPA_2": epa_scores["EPA_2"],
                        "EPA_3": epa_scores["EPA_3"],
                        "EPA_4": epa_scores["EPA_4"],
                        "EPA_5": epa_scores["EPA_5"],
                        "è©•èª": comments,
                        "æäº¤æ™‚é–“": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    
                    # å°‡è³‡æ–™è½‰æ›ç‚º DataFrame
                    df = pd.DataFrame([form_data])
                    
                    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                    try:
                        # å¦‚æœæª”æ¡ˆå­˜åœ¨ï¼Œè®€å–ä¸¦é™„åŠ æ–°è³‡æ–™
                        existing_df = pd.read_csv("test_form_data.csv")
                        df = pd.concat([existing_df, df], ignore_index=True)
                    except FileNotFoundError:
                        # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨æ–°è³‡æ–™
                        pass
                    
                    # å„²å­˜åˆ° CSV æª”æ¡ˆ
                    df.to_csv("test_form_data.csv", index=False, encoding='utf-8-sig')
                    
                    # å„²å­˜åˆ° SQLite è³‡æ–™åº«
                    if init_test_form_db():
                        if save_to_sqlite(form_data):
                            st.success("è³‡æ–™å·²æˆåŠŸå„²å­˜åˆ°æœ¬æ©Ÿè³‡æ–™åº«ï¼")
                        else:
                            st.warning("è³‡æ–™å·²å„²å­˜åˆ° CSVï¼Œä½†è³‡æ–™åº«å„²å­˜å¤±æ•—")
                    else:
                        st.warning("è³‡æ–™å·²å„²å­˜åˆ° CSVï¼Œä½†è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—")
                    
                    # é¡¯ç¤ºæˆåŠŸè¨Šæ¯
                    st.success("è¡¨å–®æäº¤æˆåŠŸï¼")
                    # é¡¯ç¤ºæäº¤çš„è³‡æ–™
                    st.write("æäº¤çš„è³‡æ–™ï¼š")
                    st.write(f"å§“åï¼š{name}")
                    st.write(f"æ¢¯æ¬¡ï¼š{batch}")
                    st.write("EPA è©•åˆ†ï¼š", epa_scores)
                    st.write("è©•èªï¼š", comments)
        
        with test_result_tab:
            st.header("æ¸¬è©¦çµæœåˆ†æ")
            
            try:
                # è®€å– CSV æª”æ¡ˆ
                df = pd.read_csv("test_form_data.csv")
                
                # é¡¯ç¤ºåŸå§‹è³‡æ–™
                st.subheader("åŸå§‹è³‡æ–™")
                st.dataframe(df)
                
                # EPA è©•åˆ†çµ±è¨ˆ
                st.subheader("EPA è©•åˆ†çµ±è¨ˆ")
                epa_columns = [f"EPA_{i}" for i in range(1, 6)]
                epa_stats = df[epa_columns].describe()
                st.dataframe(epa_stats)
                
                # EPA å¹³å‡åˆ†æ•¸é›·é”åœ–
                st.subheader("EPA å¹³å‡åˆ†æ•¸é›·é”åœ–")
                epa_means = df[epa_columns].mean()
                
                fig = go.Figure()
                fig.add_trace(go.Scatterpolar(
                    r=epa_means.values,
                    theta=[f"EPA {i}" for i in range(1, 6)],
                    fill='toself',
                    name='å¹³å‡åˆ†æ•¸',
                    hovertemplate='EPA: %{theta}<br>å¹³å‡åˆ†æ•¸: %{r:.2f}<extra></extra>'
                ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, 5],
                            ticktext=['1', '2', '3', '4', '5'],
                            tickvals=[1, 2, 3, 4, 5]
                        )
                    ),
                    showlegend=False,
                    title="EPA å¹³å‡åˆ†æ•¸é›·é”åœ–",
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # EPA è©•åˆ†è¶¨å‹¢åœ–
                st.subheader("EPA è©•åˆ†è¶¨å‹¢ï¼ˆæŒ‰æ¢¯æ¬¡ï¼‰")
                
                # æŒ‰ç…§æ¢¯æ¬¡åˆ†çµ„è¨ˆç®—å¹³å‡åˆ†æ•¸
                epa_trend = df.groupby('æ¢¯æ¬¡')[epa_columns].mean().reset_index()
                
                fig = go.Figure()
                
                colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # è‡ªå®šç¾©é¡è‰²
                
                for i, epa in enumerate(epa_columns):
                    fig.add_trace(go.Scatter(
                        x=epa_trend['æ¢¯æ¬¡'],
                        y=epa_trend[epa],
                        mode='lines+markers',
                        name=f'EPA {i+1}',
                        line=dict(width=3, color=colors[i]),
                        marker=dict(size=10, symbol='circle', color=colors[i]),
                        hovertemplate='æ¢¯æ¬¡: %{x}<br>å¹³å‡åˆ†æ•¸: %{y:.2f}<extra></extra>'
                    ))
                
                fig.update_layout(
                    title=dict(
                        text="EPA è©•åˆ†è¶¨å‹¢ï¼ˆæŒ‰æ¢¯æ¬¡ï¼‰",
                        font=dict(size=24)
                    ),
                    xaxis=dict(
                        title="æ¢¯æ¬¡",
                        categoryorder='array',
                        categoryarray=['2025/02', '2025/03', '2025/04'],
                        tickfont=dict(size=14),
                        gridcolor='lightgrey'
                    ),
                    yaxis=dict(
                        title="å¹³å‡åˆ†æ•¸",
                        range=[1, 5],
                        tickmode='linear',
                        tick0=1,
                        dtick=1,
                        tickfont=dict(size=14),
                        gridcolor='lightgrey'
                    ),
                    hovermode="x unified",
                    showlegend=True,
                    legend=dict(
                        font=dict(size=12),
                        yanchor="top",
                        y=0.99,
                        xanchor="right",
                        x=0.99
                    ),
                    height=600,
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    margin=dict(t=100)
                )
                
                # æ·»åŠ ç¶²æ ¼ç·š
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey')
                
                st.plotly_chart(fig, use_container_width=True)
                
                # EPA è©•åˆ†åˆ†å¸ƒåœ–
                st.subheader("EPA è©•åˆ†åˆ†å¸ƒ")
                fig = make_subplots(rows=2, cols=3, subplot_titles=[f"{epa} åˆ†å¸ƒ" for epa in epa_columns])
                
                for i, epa in enumerate(epa_columns):
                    row = (i // 3) + 1
                    col = (i % 3) + 1
                    
                    fig.add_trace(
                        go.Histogram(
                            x=df[epa],
                            nbinsx=5,
                            name=epa,
                            hovertemplate='è©•åˆ†: %{x}<br>æ¬¡æ•¸: %{y}<extra></extra>'
                        ),
                        row=row, col=col
                    )
                
                fig.update_layout(
                    height=800,
                    showlegend=False,
                    title_text="EPA è©•åˆ†åˆ†å¸ƒ"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # è©•èªåˆ†æ
                st.subheader("è©•èªåˆ†æ")
                if not df['è©•èª'].empty:
                    st.write("æœ€è¿‘ 5 ç­†è©•èªï¼š")
                    for comment in df['è©•èª'].tail(5):
                        st.write(f"- {comment}")
                
            except FileNotFoundError:
                st.warning("å°šæœªæœ‰æ¸¬è©¦è³‡æ–™ï¼Œè«‹å…ˆå¡«å¯«è¡¨å–®ã€‚")
            except Exception as e:
                st.error(f"è®€å–æˆ–åˆ†æè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return
    
    # é¡¯ç¤ºç™»å‡ºæŒ‰éˆ•
    with st.sidebar:
        if st.button("ç™»å‡º"):
            st.session_state.logged_in = False
            st.session_state.username = None
            st.session_state.role = None
            st.session_state.user_name = None
            st.session_state.user_department = None
            st.session_state.student_id = None
            st.rerun()
    
    st.title("å­¸ç”Ÿè©•æ ¸ç³»çµ±")
    
    # å®šç¾©ç§‘åˆ¥åˆ—è¡¨
    departments = [
        "å°å…’éƒ¨", 
        "å…§ç§‘", 
        "å¤–ç§‘", 
        "å©¦ç”¢ç§‘", 
        "ç¥ç¶“ç§‘", 
        "ç²¾ç¥ç§‘", 
        "å®¶é†«ç§‘", 
        "æ€¥è¨ºé†«å­¸ç§‘", 
        "éº»é†‰ç§‘", 
        "æ”¾å°„ç§‘", 
        "ç—…ç†ç§‘", 
        "å¾©å¥ç§‘", 
        "çš®è†šç§‘", 
        "çœ¼ç§‘", 
        "è€³é¼»å–‰ç§‘", 
        "æ³Œå°¿ç§‘", 
        "éª¨ç§‘", 
        "å…¶ä»–ç§‘åˆ¥"
    ]
    
    # ç²å–ä½¿ç”¨è€…ç§‘åˆ¥
    user_department = st.session_state.get('user_department', None)
    
    # å´é‚Šæ¬„è¨­ç½®
    with st.sidebar:
        st.header("è³‡æ–™ä¾†æºé¸æ“‡")
        
        st.header("ç§‘åˆ¥é¸æ“‡")
        
        # ç§‘åˆ¥é¸æ“‡ - æ ¹æ“šæ¬Šé™é™åˆ¶å¯é¸æ“‡çš„ç§‘åˆ¥
        if check_permission(st.session_state.role, 'can_view_all'):
            # ç®¡ç†å“¡å¯ä»¥é¸æ“‡æ‰€æœ‰ç§‘åˆ¥
            available_departments = departments
        elif st.session_state.role == 'teacher' and user_department:
            # ä¸»æ²»é†«å¸«åªèƒ½é¸æ“‡è‡ªå·±çš„ç§‘åˆ¥
            available_departments = [user_department]
        else:
            # å…¶ä»–è§’è‰²åªèƒ½é¸æ“‡è‡ªå·±çš„ç§‘åˆ¥ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            available_departments = [user_department] if user_department else departments
        
        selected_dept = st.selectbox(
            "è«‹é¸æ“‡ç§‘åˆ¥",
            available_departments
        )
        
        # æ ¹æ“šæ¬Šé™é¡¯ç¤ºä¸Šå‚³å€åŸŸ
        if check_permission(st.session_state.role, 'can_upload_files'):
            st.subheader(f"{selected_dept}è©•æ ¸è³‡æ–™")
            
            # æª”æ¡ˆä¸Šå‚³å€åŸŸ
            uploaded_files = st.file_uploader(
                f"è«‹ä¸Šå‚³{selected_dept} Excelæª”æ¡ˆ",
                type=['xlsx', 'xls'],
                accept_multiple_files=True,
                key=f"{selected_dept}_files"
            )
            
            if st.button(f"åˆä½µ{selected_dept}æª”æ¡ˆ") and uploaded_files:
                result = merge_excel_files(uploaded_files)
                if result is not None:
                    st.success(f"{selected_dept}æª”æ¡ˆåˆä½µæˆåŠŸï¼")
                    # å°‡è³‡æ–™å­˜å…¥ session stateï¼Œä½¿ç”¨ç§‘åˆ¥ä½œç‚º key
                    st.session_state[f"{selected_dept}_data"] = result
                    st.session_state.merged_data = result
                else:
                    st.error(f"{selected_dept}æª”æ¡ˆåˆä½µå¤±æ•—ï¼")
        
        # é¡¯ç¤ºå·²ä¸Šå‚³çš„ç§‘åˆ¥ - æ ¹æ“šæ¬Šé™éæ¿¾
        if check_permission(st.session_state.role, 'can_view_all'):
            st.subheader("å·²ä¸Šå‚³çš„ç§‘åˆ¥")
            uploaded_depts = [dept for dept in departments if f"{dept}_data" in st.session_state]
            if uploaded_depts:
                for dept in uploaded_depts:
                    st.write(f"âœ… {dept}")
            else:
                st.write("å°šæœªä¸Šå‚³ä»»ä½•ç§‘åˆ¥è³‡æ–™")
        elif st.session_state.role == 'teacher' and user_department:
            # ä¸»æ²»é†«å¸«åªèƒ½çœ‹åˆ°è‡ªå·±ç§‘çš„è³‡æ–™
            st.subheader("å·²ä¸Šå‚³çš„ç§‘åˆ¥")
            if f"{user_department}_data" in st.session_state:
                st.write(f"âœ… {user_department}")
            else:
                st.write(f"å°šæœªä¸Šå‚³ {user_department} çš„è³‡æ–™")
        
        # ç³»çµ±ç®¡ç†å“¡å¯ä»¥ç®¡ç†ä½¿ç”¨è€…
        if check_permission(st.session_state.role, 'can_manage_users'):
            st.markdown("---")
            show_user_management()
        
        # æ·»åŠ æ¸¬è©¦ç³»çµ±é€£çµ
        st.markdown("---")
        st.subheader("æ¸¬è©¦ç³»çµ±")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å¡«å¯«è¡¨å–®æ¸¬è©¦", key="sidebar_form_button"):
                st.markdown('<meta http-equiv="refresh" content="0;URL=test_form">', unsafe_allow_html=True)
        with col2:
            if st.button("æŸ¥çœ‹æ¸¬è©¦çµæœ", key="sidebar_result_button"):
                st.markdown('<meta http-equiv="refresh" content="0;URL=test_results">', unsafe_allow_html=True)

    # åˆ†é è¨­ç½® - æ ¹æ“šæ¬Šé™é¡¯ç¤ºä¸åŒçš„åˆ†é 
    tab_names = []
    
    # æ ¹æ“šè§’è‰²å’Œæ¬Šé™é¡¯ç¤ºä¸åŒçš„åˆ†é 
    if check_permission(st.session_state.role, 'can_view_all'):
        # ç®¡ç†å“¡å¯ä»¥çœ‹åˆ°æ‰€æœ‰è³‡æ–™
        tab_names.append("UGY")
        tab_names.append("PGY")
        tab_names.append("ä½é™¢é†«å¸«")
        tab_names.append("è€å¸«è©•åˆ†åˆ†æ")
    elif check_permission(st.session_state.role, 'can_view_ugy_data'):
        # ä¸»æ²»é†«å¸«å’Œä½é™¢é†«å¸«å¯ä»¥çœ‹åˆ°UGYè³‡æ–™
        tab_names.append("UGY")
        
        if check_permission(st.session_state.role, 'can_view_pgy_data'):
            tab_names.append("PGY")
        
        if check_permission(st.session_state.role, 'can_view_resident_data'):
            tab_names.append("ä½é™¢é†«å¸«")
        
        if check_permission(st.session_state.role, 'can_view_analytics'):
            tab_names.append("è€å¸«è©•åˆ†åˆ†æ")
    elif st.session_state.role == 'student':
        # UGYåªèƒ½çœ‹åˆ°è‡ªå·±çš„è³‡æ–™
        tab_names.append("æˆ‘çš„è©•æ ¸è³‡æ–™")
    
    if not tab_names:
        st.warning("æ‚¨æ²’æœ‰æ¬Šé™æŸ¥çœ‹ä»»ä½•è³‡æ–™")
        return
    
    # æ ¹æ“šè§’è‰²å‹•æ…‹å‰µå»ºåˆ†é 
    if st.session_state.role == 'student':
        # UGYç¾åœ¨ä¹Ÿå¯èƒ½æœ‰å¤šå€‹åˆ†é 
        tabs = st.tabs(tab_names)
        
        # æ ¹æ“šåˆ†é åç¨±å‹•æ…‹è™•ç†å…§å®¹
        for i, tab_name in enumerate(tab_names):
            with tabs[i]:
                if tab_name == "æˆ‘çš„è©•æ ¸è³‡æ–™":
                    st.header("æˆ‘çš„è©•æ ¸è³‡æ–™")
                    # å¾ session state ä¸­ç²å–æ‰€æœ‰ç§‘åˆ¥çš„è³‡æ–™
                    all_data = []
                    for dept in departments:
                        if f"{dept}_data" in st.session_state:
                            all_data.append(st.session_state[f"{dept}_data"])
                    
                    if all_data:
                        # åˆä½µæ‰€æœ‰ç§‘åˆ¥çš„è³‡æ–™
                        current_data = pd.concat(all_data, ignore_index=True)
                        # éæ¿¾å‡ºè©²å­¸ç”Ÿçš„è³‡æ–™
                        student_data = current_data[current_data['å­¸è™Ÿ'] == st.session_state.get('student_id')]
                        if not student_data.empty:
                            # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
                            st.subheader("åŸºæœ¬è³‡è¨Š")
                            st.write(f"å§“åï¼š{student_data['å§“å'].iloc[0]}")
                            st.write(f"å­¸è™Ÿï¼š{student_data['å­¸è™Ÿ'].iloc[0]}")
                            st.write(f"ç§‘åˆ¥ï¼š{student_data['ç§‘åˆ¥'].iloc[0]}")
                            
                            # é¡¯ç¤º EPA è©•åˆ†
                            st.subheader("EPA è©•åˆ†")
                            epa_columns = [col for col in student_data.columns if 'EPA' in col]
                            for epa_col in epa_columns:
                                st.write(f"{epa_col}ï¼š{student_data[epa_col].iloc[0]}")
                            
                            # é¡¯ç¤ºè©•èª
                            if 'è©•èª' in student_data.columns:
                                st.subheader("è©•èª")
                                st.write(student_data['è©•èª'].iloc[0])
                            
                            # é¡¯ç¤ºè¶¨å‹¢åœ–
                            st.subheader("è©•åˆ†è¶¨å‹¢")
                            if len(student_data) > 1:  # ç¢ºä¿æœ‰å¤šç­†è³‡æ–™æ‰é¡¯ç¤ºè¶¨å‹¢åœ–
                                trend_data = student_data[epa_columns].T
                                trend_data.columns = ['è©•åˆ†']
                                st.line_chart(trend_data)
                            
                            # é¡¯ç¤ºé›·é”åœ–
                            st.subheader("èƒ½åŠ›é›·é”åœ–")
                            if epa_columns:
                                radar_data = student_data[epa_columns].iloc[0]
                                fig = go.Figure()
                                fig.add_trace(go.Scatterpolar(
                                    r=radar_data.values,
                                    theta=radar_data.index,
                                    fill='toself',
                                    name='èƒ½åŠ›è©•åˆ†'
                                ))
                                fig.update_layout(
                                    polar=dict(
                                        radialaxis=dict(
                                            visible=True,
                                            range=[0, 5]
                                        )
                                    ),
                                    showlegend=False
                                )
                                st.plotly_chart(fig)
                        else:
                            st.warning("æ‰¾ä¸åˆ°æ‚¨çš„è©•æ ¸è³‡æ–™")
                    else:
                        st.warning("å°šæœªä¸Šå‚³ä»»ä½•è©•æ ¸è³‡æ–™")
                
                elif tab_name == "UGY":
                    if check_permission(st.session_state.role, 'can_view_ugy_data'):
                        # æ ¹æ“šè§’è‰²æ±ºå®šé¡¯ç¤ºçš„åˆ†é 
                        if st.session_state.role == 'student':
                            # å­¸ç”Ÿå¸³è™Ÿåªé¡¯ç¤ºå€‹åˆ¥å­¸ç”Ÿåˆ†æ
                            st.header("æˆ‘çš„è©•æ ¸è³‡æ–™åˆ†æ")
                            show_ugy_student_analysis()
                        else:
                            # å…¶ä»–è§’è‰²é¡¯ç¤ºå®Œæ•´çš„åˆ†é 
                            ugy_subtabs = st.tabs(["å­¸ç”Ÿç¸½è¦½", "å€‹åˆ¥å­¸ç”Ÿåˆ†æ"])
                            
                            with ugy_subtabs[0]:
                                st.header("å­¸ç”Ÿç¸½è¦½")
                                show_ugy_student_overview()
                            
                            with ugy_subtabs[1]:
                                st.header("å€‹åˆ¥å­¸ç”Ÿåˆ†æ")
                                show_ugy_student_analysis()
    else:
        # ç‚ºéå­¸ç”Ÿè§’è‰²æº–å‚™ current_data
        current_data = None
        all_data = []
        for dept in departments:
            if f"{dept}_data" in st.session_state:
                all_data.append(st.session_state[f"{dept}_data"])
        
        if all_data:
            current_data = pd.concat(all_data, ignore_index=True)
        
        # å‹•æ…‹å‰µå»ºåˆ†é 
        tabs = st.tabs(tab_names)
        
        # æ ¹æ“šåˆ†é åç¨±å‹•æ…‹è™•ç†å…§å®¹
        for i, tab_name in enumerate(tab_names):
            with tabs[i]:
                if tab_name == "UGY":
                    if check_permission(st.session_state.role, 'can_view_all') or check_permission(st.session_state.role, 'can_view_ugy_data'):
                        # æ ¹æ“šè§’è‰²æ±ºå®šé¡¯ç¤ºçš„åˆ†é 
                        if st.session_state.role == 'student':
                            # å­¸ç”Ÿå¸³è™Ÿåªé¡¯ç¤ºå€‹åˆ¥å­¸ç”Ÿåˆ†æ
                            st.header("æˆ‘çš„è©•æ ¸è³‡æ–™åˆ†æ")
                            show_ugy_student_analysis()
                        else:
                            # å…¶ä»–è§’è‰²é¡¯ç¤ºå®Œæ•´çš„åˆ†é 
                            ugy_subtabs = st.tabs(["å­¸ç”Ÿç¸½è¦½", "å€‹åˆ¥å­¸ç”Ÿåˆ†æ"])
                            
                            with ugy_subtabs[0]:
                                st.header("å­¸ç”Ÿç¸½è¦½")
                                show_ugy_student_overview()
                            
                            with ugy_subtabs[1]:
                                st.header("å€‹åˆ¥å­¸ç”Ÿåˆ†æ")
                                show_ugy_student_analysis()
                
                elif tab_name == "PGY":
                    if check_permission(st.session_state.role, 'can_view_pgy_data'):
                        st.header("PGY åˆ†æ")
                        if current_data is not None:
                            pgy_data = current_data[current_data['æª”æ¡ˆåç¨±'].str.contains('PGY', case=False, na=False)]
                            if not pgy_data.empty:
                                # æ ¹æ“šæ¬Šé™éæ¿¾PGYè³‡æ–™
                                filtered_pgy_data = filter_data_by_permission(pgy_data, st.session_state.role, user_department, 'pgy')
                                if not filtered_pgy_data.empty:
                                    show_analysis_section(filtered_pgy_data)
                                else:
                                    st.warning("æ‚¨æ²’æœ‰æ¬Šé™æŸ¥çœ‹æ­¤è³‡æ–™")
                            else:
                                st.warning("æ²’æœ‰ PGY è³‡æ–™")
                        else:
                            st.warning("è«‹å…ˆè¼‰å…¥è³‡æ–™")
                
                elif tab_name == "ä½é™¢é†«å¸«":
                    if check_permission(st.session_state.role, 'can_view_resident_data') or check_permission(st.session_state.role, 'can_view_all'):
                        # æª¢æŸ¥æ˜¯å¦é¸æ“‡å°å…’éƒ¨
                        if selected_dept == "å°å…’éƒ¨":
                            # ç›´æ¥é¡¯ç¤ºå°å…’éƒ¨è©•æ ¸ç³»çµ±
                            from analysis_pediatric import show_pediatric_evaluation_section
                            show_pediatric_evaluation_section()
                        else:
                            # é¡¯ç¤ºä¸€èˆ¬ä½é™¢é†«å¸«åˆ†æ
                            st.header("ä½é™¢é†«å¸«åˆ†æ")
                            if current_data is not None:
                                r_data = current_data[current_data['æª”æ¡ˆåç¨±'].str.contains('R', case=False, na=False)]
                                if not r_data.empty:
                                    # æ ¹æ“šæ¬Šé™éæ¿¾ä½é™¢é†«å¸«è³‡æ–™
                                    filtered_r_data = filter_data_by_permission(r_data, st.session_state.role, user_department, 'resident')
                                    if not filtered_r_data.empty:
                                        if selected_dept == "éº»é†‰ç§‘":
                                            show_ANE_R_EPA_peer_analysis_section(filtered_r_data)
                                        else:
                                            show_resident_analysis_section(filtered_r_data)
                                    else:
                                        st.warning("æ‚¨æ²’æœ‰æ¬Šé™æŸ¥çœ‹æ­¤è³‡æ–™")
                                else:
                                    st.warning("æ²’æœ‰ä½é™¢é†«å¸«è³‡æ–™")
                            else:
                                st.warning("è«‹å…ˆè¼‰å…¥è³‡æ–™")
                
                elif tab_name == "è€å¸«è©•åˆ†åˆ†æ":
                    if check_permission(st.session_state.role, 'can_view_analytics'):
                        show_teacher_analysis_section()

if __name__ == "__main__":
    main()

# streamlit run main_dashboard.py

# GitHub æ›´æ–°æŒ‡ä»¤èªªæ˜
# 1. åˆæ¬¡è¨­å®š
# git init  # åˆå§‹åŒ– git å€‰åº«
# git remote add origin <repository_url>  # é€£æ¥é ç«¯å€‰åº«

# 2. æ›´æ–°æµç¨‹
# git add .  # åŠ å…¥æ‰€æœ‰ä¿®æ”¹çš„æª”æ¡ˆ
# git commit -m "æ›´æ–°èªªæ˜"  # æäº¤ä¿®æ”¹ä¸¦åŠ å…¥èªªæ˜
# git push origin main  # æ¨é€åˆ° GitHub ä¸»åˆ†æ”¯

# 3. å¦‚æœé‡åˆ°è¡çª
# git pull origin main  # å…ˆæ‹‰å–æœ€æ–°ç‰ˆæœ¬
# è§£æ±ºè¡çªå¾Œå†åŸ·è¡Œæ­¥é©Ÿ 2

# 4. æŸ¥çœ‹ç‹€æ…‹
# git status  # æª¢æŸ¥æª”æ¡ˆç‹€æ…‹
# git log  # æŸ¥çœ‹æäº¤æ­·å² 

